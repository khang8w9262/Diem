# Enhanced Major Prediction vá»›i 5 ngÃ nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c cao
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import random

def enhanced_major_calculation():
    """
    TÃ­nh toÃ¡n ngÃ nh phÃ¹ há»£p vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ Ä‘á»§ 5 ngÃ nh
    """
    print("ğŸ”„ TÃ­nh toÃ¡n ngÃ nh phÃ¹ há»£p vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n...")
    
    # Äá»c dá»¯ liá»‡u
    df_processed = pd.read_csv('Data/student_grades_5000.csv')
    df_weights = pd.read_excel('Data/1.xlsx').head(42)
    
    # TÃªn ngÃ nh vÃ  mapping
    major_cols = ['CNPM', 'Máº¡ng ', 'An toÃ n ', 'Há»‡ thá»‘ng ', 'MÃ¡y há»c']
    major_names = ['CNPM', 'Mang', 'An_toan', 'He_thong', 'May_hoc']
    
    results = []
    major_counts = {name: 0 for name in major_names}
    
    # ThÃªm random seed Ä‘á»ƒ cÃ³ thá»ƒ tÃ¡i táº¡o
    random.seed(42)
    np.random.seed(42)
    
    for idx in range(len(df_processed.columns) - 2):  # Trá»« STT vÃ  Subject
        if idx == 0:  # STT column
            continue
            
        student_col = df_processed.columns[idx + 1]  # Skip STT
        if not student_col.startswith('SV'):
            continue
            
        student_record = {'MSSV': student_col}
        
        # Láº¥y Ä‘iá»ƒm tá»«ng mÃ´n
        subject_scores = df_processed[student_col].values
        
        # TÃ­nh Ä‘iá»ƒm cho tá»«ng ngÃ nh vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n
        major_scores = {}
        
        for i, major_col in enumerate(major_cols):
            major_name = major_names[i]
            total_score = 0
            total_weight = 0
            
            for j in range(42):
                score = subject_scores[j]
                weight = df_weights.iloc[j][major_col] if pd.notna(df_weights.iloc[j][major_col]) else 0
                
                if score > 0:  # Chá»‰ tÃ­nh mÃ´n khÃ´ng rá»›t
                    # Sá»­ dá»¥ng trá»ng sá»‘ vÃ  Ä‘iá»ƒm vá»›i cÃ´ng thá»©c cáº£i tiáº¿n
                    weighted_score = score * (1 + weight * 0.5)  # TÄƒng áº£nh hÆ°á»Ÿng cá»§a trá»ng sá»‘
                    total_score += weighted_score
                    total_weight += (1 + weight * 0.5)
            
            if total_weight > 0:
                major_scores[major_name] = total_score / total_weight
            else:
                major_scores[major_name] = 0
        
        # ThÃªm yáº¿u tá»‘ random nhá» Ä‘á»ƒ trÃ¡nh tie
        for major_name in major_names:
            major_scores[major_name] += random.uniform(0, 0.001)
        
        # CÃ¢n báº±ng phÃ¢n bá»‘ ngÃ nh
        # Náº¿u má»™t ngÃ nh cÃ³ quÃ¡ Ã­t sinh viÃªn, tÄƒng Ä‘iá»ƒm cho nÃ³
        min_count = min(major_counts.values())
        max_count = max(major_counts.values())
        
        if max_count - min_count > 200:  # Náº¿u chÃªnh lá»‡ch quÃ¡ lá»›n
            # TÃ¬m ngÃ nh cÃ³ Ã­t sinh viÃªn nháº¥t
            min_major = min(major_counts, key=major_counts.get)
            # TÄƒng Ä‘iá»ƒm cho ngÃ nh nÃ y
            major_scores[min_major] += 0.1
        
        # TÃ¬m ngÃ nh cÃ³ Ä‘iá»ƒm cao nháº¥t
        if any(score > 0 for score in major_scores.values()):
            best_major = max(major_scores, key=major_scores.get)
            best_score = major_scores[best_major]
            major_counts[best_major] += 1
        else:
            best_major = 'Khong_xac_dinh'
            best_score = 0
        
        # LÆ°u káº¿t quáº£
        student_record['Nganh_phu_hop'] = best_major
        student_record['Diem_phu_hop'] = best_score
        
        # ThÃªm Ä‘iá»ƒm tá»«ng ngÃ nh
        for major_name in major_names:
            student_record[f'Score_{major_name}'] = major_scores[major_name]
        
        # TÃ­nh cÃ¡c Ä‘áº·c trÆ°ng
        non_zero_scores = subject_scores[subject_scores > 0]
        student_record['GPA'] = np.mean(non_zero_scores) if len(non_zero_scores) > 0 else 0
        student_record['Failed_Subjects'] = len(subject_scores[subject_scores == 0])
        student_record['Pass_Rate'] = len(non_zero_scores) / len(subject_scores)
        
        # NhÃ³m mÃ´n
        math_physics = subject_scores[:10]
        student_record['Math_Physics_Avg'] = np.mean(math_physics[math_physics > 0]) if len(math_physics[math_physics > 0]) > 0 else 0
        
        programming = subject_scores[10:20]
        student_record['Programming_Avg'] = np.mean(programming[programming > 0]) if len(programming[programming > 0]) > 0 else 0
        
        network_security = subject_scores[20:30]
        student_record['Network_Security_Avg'] = np.mean(network_security[network_security > 0]) if len(network_security[network_security > 0]) > 0 else 0
        
        system_ai = subject_scores[30:]
        student_record['System_AI_Avg'] = np.mean(system_ai[system_ai > 0]) if len(system_ai[system_ai > 0]) > 0 else 0
        
        # ThÃªm Ä‘iá»ƒm tá»«ng mÃ´n
        for i in range(42):
            student_record[f'Mon_{i+1:02d}'] = subject_scores[i]
        
        results.append(student_record)
        
        if len(results) % 1000 == 0:
            print(f"âœ… ÄÃ£ xá»­ lÃ½ {len(results)} sinh viÃªn")
            print(f"ğŸ“Š PhÃ¢n bá»‘ hiá»‡n táº¡i: {major_counts}")
    
    df_results = pd.DataFrame(results)
    
    # LÆ°u káº¿t quáº£
    output_file = 'Data/student_major_predictions_5000.csv'
    df_results.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"\nâœ… HoÃ n thÃ nh! ÄÃ£ xá»­ lÃ½ {len(df_results)} sinh viÃªn")
    print(f"ğŸ’¾ ÄÃ£ lÆ°u vÃ o: {output_file}")
    
    # Thá»‘ng kÃª phÃ¢n bá»‘ ngÃ nh
    print("\nğŸ“Š PhÃ¢n bá»‘ ngÃ nh phÃ¹ há»£p:")
    major_dist = df_results['Nganh_phu_hop'].value_counts()
    for major, count in major_dist.items():
        print(f"   â€¢ {major}: {count} sinh viÃªn ({count/len(df_results)*100:.1f}%)")
    
    return df_results

def train_enhanced_lgbm_model():
    """
    Huáº¥n luyá»‡n model LightGBM vá»›i hyperparameters tá»‘i Æ°u Ä‘á»ƒ Ä‘áº¡t 90%+ accuracy
    """
    print("ğŸ”„ Huáº¥n luyá»‡n model LightGBM vá»›i hyperparameters tá»‘i Æ°u...")
    
    # Äá»c dá»¯ liá»‡u
    df = pd.read_csv('Data/student_major_predictions_5000.csv')
    
    # Loáº¡i bá» sinh viÃªn khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c ngÃ nh
    df_clean = df[df['Nganh_phu_hop'] != 'Khong_xac_dinh'].copy()
    print(f"ğŸ“Š Dá»¯ liá»‡u sau khi lÃ m sáº¡ch: {len(df_clean)} sinh viÃªn")
    
    # Chá»n Ä‘áº·c trÆ°ng
    feature_cols = (
        [f'Mon_{i+1:02d}' for i in range(42)] +  # Äiá»ƒm 42 mÃ´n
        ['GPA', 'Failed_Subjects', 'Pass_Rate'] +  # Äáº·c trÆ°ng tá»•ng há»£p
        ['Math_Physics_Avg', 'Programming_Avg', 'Network_Security_Avg', 'System_AI_Avg'] +  # Äiá»ƒm theo nhÃ³m
        [f'Score_{major}' for major in ['CNPM', 'Mang', 'An_toan', 'He_thong', 'May_hoc']]  # Äiá»ƒm tá»«ng ngÃ nh
    )
    
    X = df_clean[feature_cols]
    y = df_clean['Nganh_phu_hop']
    
    # Encode target
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    print(f"ğŸ“Š Sá»‘ ngÃ nh: {len(label_encoder.classes_)}")
    print(f"ğŸ“‹ CÃ¡c ngÃ nh: {list(label_encoder.classes_)}")
    
    # Chia train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    # Hyperparameters tá»‘i Æ°u cho accuracy cao
    best_params = {
        'objective': 'multiclass',
        'num_class': len(label_encoder.classes_),
        'metric': 'multi_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 127,  # TÄƒng Ä‘á»ƒ model phá»©c táº¡p hÆ¡n
        'learning_rate': 0.02,  # Giáº£m learning rate
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'min_data_in_leaf': 10,
        'lambda_l1': 0.1,
        'lambda_l2': 0.1,
        'verbose': -1,
        'random_state': 42
    }
    
    # Táº¡o datasets
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    # Huáº¥n luyá»‡n model
    model = lgb.train(
        best_params,
        train_data,
        valid_sets=[train_data, valid_data],
        valid_names=['train', 'eval'],
        num_boost_round=2000,  # TÄƒng sá»‘ rounds
        callbacks=[
            lgb.early_stopping(stopping_rounds=100),
            lgb.log_evaluation(period=200)
        ]
    )
    
    # ÄÃ¡nh giÃ¡
    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = np.argmax(y_pred_proba, axis=1)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ¯ Äá»™ chÃ­nh xÃ¡c: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # LÆ°u model vÃ  cÃ¡c thÃ nh pháº§n
    model.save_model('Data/lgbm_major_prediction_model.txt')
    
    import pickle
    with open('Data/label_encoder.pkl', 'wb') as f:
        pickle.dump(label_encoder, f)
    
    with open('Data/feature_cols.pkl', 'wb') as f:
        pickle.dump(feature_cols, f)
    
    print("ğŸ’¾ ÄÃ£ lÆ°u model vÃ  cÃ¡c thÃ nh pháº§n vÃ o thÆ° má»¥c Data/")
    
    # BÃ¡o cÃ¡o chi tiáº¿t
    print("\nğŸ“Š BÃ¡o cÃ¡o chi tiáº¿t:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))
    
    return model, label_encoder, feature_cols, accuracy

def create_comparison_file():
    """
    Táº¡o file so sÃ¡nh giá»¯a LightGBM vÃ  Major Prediction
    """
    print("ğŸ”„ Táº¡o file so sÃ¡nh...")
    
    # Äá»c dá»¯ liá»‡u gá»‘c
    df_lgbm = pd.read_csv('Data/student_major_predictions_5000.csv')
    
    # Láº¥y 1000 máº«u ngáº«u nhiÃªn Ä‘á»ƒ so sÃ¡nh
    df_sample = df_lgbm.sample(n=1000, random_state=42).reset_index(drop=True)
    
    # Load model Ä‘á»ƒ dá»± bÃ¡o
    try:
        import pickle
        model = lgb.Booster(model_file='Data/lgbm_major_prediction_model.txt')
        
        with open('Data/label_encoder.pkl', 'rb') as f:
            label_encoder = pickle.load(f)
        
        with open('Data/feature_cols.pkl', 'rb') as f:
            feature_cols = pickle.load(f)
        
        # Dá»± bÃ¡o báº±ng LightGBM
        X_sample = df_sample[feature_cols]
        y_pred_proba = model.predict(X_sample, num_iteration=model.best_iteration)
        y_pred = np.argmax(y_pred_proba, axis=1)
        lgbm_predictions = label_encoder.inverse_transform(y_pred)
        
        # Táº¡o DataFrame so sÃ¡nh
        comparison_data = {
            'MSSV': df_sample['MSSV'],
            'GPA': df_sample['GPA'],
            'Failed_Subjects': df_sample['Failed_Subjects'],
            'Major_Prediction': df_sample['Nganh_phu_hop'],
            'LightGBM_Prediction': lgbm_predictions,
            'Match': df_sample['Nganh_phu_hop'] == lgbm_predictions
        }
        
        df_comparison = pd.DataFrame(comparison_data)
        
        # TÃ­nh tá»· lá»‡ trÃ¹ng khá»›p
        match_rate = df_comparison['Match'].mean()
        
        # LÆ°u file
        output_file = 'Data/comparison_lgbm_vs_major_with_analysis.csv'
        df_comparison.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"âœ… ÄÃ£ táº¡o file so sÃ¡nh: {output_file}")
        print(f"ğŸ¯ Tá»· lá»‡ trÃ¹ng khá»›p: {match_rate:.3f} ({match_rate*100:.1f}%)")
        
        # Thá»‘ng kÃª chi tiáº¿t
        print("\nğŸ“Š PhÃ¢n bá»‘ dá»± bÃ¡o LightGBM:")
        lgbm_dist = pd.Series(lgbm_predictions).value_counts()
        for major, count in lgbm_dist.items():
            print(f"   â€¢ {major}: {count} ({count/len(lgbm_predictions)*100:.1f}%)")
        
        return df_comparison, match_rate
        
    except Exception as e:
        print(f"âŒ Lá»—i khi táº¡o file so sÃ¡nh: {e}")
        return None, 0

if __name__ == "__main__":
    print("ğŸš€ Báº®T Äáº¦U QUÃ TRÃŒNH NÃ‚NG CAP Há»† THá»NG")
    print("=" * 60)
    
    # BÆ°á»›c 1: TÃ­nh toÃ¡n láº¡i ngÃ nh vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n
    enhanced_data = enhanced_major_calculation()
    
    # BÆ°á»›c 2: Huáº¥n luyá»‡n model vá»›i hyperparameters tá»‘i Æ°u
    model, encoder, features, accuracy = train_enhanced_lgbm_model()
    
    # BÆ°á»›c 3: Táº¡o file so sÃ¡nh
    comparison_df, match_rate = create_comparison_file()
    
    print("\nğŸ‰ HOÃ€N THÃ€NH NÃ‚NG Cáº¤P Há»† THá»NG!")
    print("=" * 60)
    print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c model: {accuracy*100:.2f}%")
    print(f"ğŸ¯ Tá»· lá»‡ trÃ¹ng khá»›p: {match_rate*100:.1f}%")
    print("ğŸ“„ File so sÃ¡nh Ä‘Ã£ Ä‘Æ°á»£c táº¡o trong Data/")
